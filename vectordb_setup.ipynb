{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "# import sys\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available engines: \n",
      "['whisper-1', 'babbage', 'text-davinci-003', 'davinci', 'text-davinci-edit-001', 'babbage-code-search-code', 'text-similarity-babbage-001', 'code-davinci-edit-001', 'text-davinci-001', 'gpt-4-0613', 'ada', 'babbage-code-search-text', 'babbage-similarity', 'gpt-4', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k-0613', 'code-search-babbage-text-001', 'text-curie-001', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k', 'code-search-babbage-code-001', 'text-ada-001', 'text-similarity-ada-001', 'curie-instruct-beta', 'gpt-3.5-turbo-0301', 'ada-code-search-code', 'ada-similarity', 'code-search-ada-text-001', 'text-search-ada-query-001', 'davinci-search-document', 'ada-code-search-text', 'text-search-ada-doc-001', 'davinci-instruct-beta', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-search-query', 'davinci-search-query', 'babbage-search-document', 'ada-search-document', 'text-search-curie-query-001', 'gpt-4-0314', 'text-search-babbage-doc-001', 'curie-search-document', 'text-search-curie-doc-001', 'babbage-search-query', 'text-babbage-001', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'curie-similarity', 'curie', 'text-embedding-ada-002', 'text-similarity-davinci-001', 'text-davinci-002', 'davinci-similarity']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available engines: \")\n",
    "print([data['id'] for data in openai.Engine.list()['data']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract resume names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(resume_text):\n",
    "\n",
    "    template = \"\"\"You are a helpful assistant that extracts the applicant name from the resume. Only output the full name in this format:\\n \\\n",
    "    first_name, last_name \\n\\n \"\"\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    human_template = \"Resume: \\n\\n {resume_text}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    # chat_prompt.format_messages(resume_text=\"resume_text\")\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "    name = chain.run(resume_text=resume_text)\n",
    "\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_from_file(filename):\n",
    "    # assumes the filename is in the format: firstname_lastname_resume.txt\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    names = basename.split(\"_\")\n",
    "    full_name = names[0] + \" \" + names[1]\n",
    "    return full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abraham Lincoln\n",
      "Agatha Christie\n",
      "Alberto Santos-Dumont\n",
      "Amadeo Avogadro\n",
      "Andy Warhol\n",
      "Anne Frank\n",
      "Audrey Hepburn\n",
      "Barack Obama\n",
      "Che Guevara\n",
      "Cleopatra resume\n",
      "Coco Chanel\n",
      "Dalai Lama\n",
      "David Bowie\n",
      "Diego Maradona\n",
      "Elvis Presley\n",
      "Emily Brontë\n",
      "Eva Perón\n",
      "Fidel Castro\n",
      "Freddie Mercury\n",
      "Frederick Douglass\n",
      "Galileo Galilei\n",
      "George Orwell\n",
      "George Washington\n",
      "Helen Keller\n",
      "J.K. Rowling\n",
      "Jim Morrison\n",
      "Johannes Gutenberg\n",
      "John D.\n",
      "John F.\n",
      "John Lennon\n",
      "John Steinbeck\n",
      "Joseph Stalin\n",
      "Julius Caesar\n",
      "Kurt Cobain\n",
      "Leonardo da\n",
      "Leon Trotsky\n",
      "Leo Tolstoy\n",
      "Louis Pasteur\n",
      "Mahatma Gandhi\n",
      "Mao Zedong\n",
      "Marie Antoinette\n",
      "Marie Curie\n",
      "Marlon Brando\n",
      "Martin Luther\n",
      "Michael Jordan\n",
      "Mikhail Gorbachev\n",
      "Muhammad Ali\n",
      "Nelson Mandela\n",
      "Nikola Tesla\n",
      "Oprah Winfrey\n",
      "Pierre-Auguste Renoir\n",
      "Pierre Curie\n",
      "Plato resume\n",
      "Pope Francis\n",
      "Princess Diana\n",
      "Queen Elizabeth\n",
      "Roger Federer\n",
      "Rosalind Franklin\n",
      "Rosa Parks\n",
      "Stephen Hawking\n",
      "Steve Jobs\n",
      "Thomas Edison\n",
      "Virginia Woolf\n",
      "Vladimir Lenin\n",
      "Walt Disney\n",
      "Winston Churchill\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = r\"resume_data\"\n",
    "metadata_list = []\n",
    "\n",
    "name_list = []\n",
    "# iterate over files in that directory\n",
    "for filename in os.listdir(path):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    if os.path.isfile(file_path) and (filename != \".DS_Store\"):\n",
    "        # print(f'Loading file: {file_path}')\n",
    "        full_name = get_name_from_file(filename)\n",
    "        print(full_name)\n",
    "        metadata = {\"filename\": filename, \"full_name\": full_name}\n",
    "        metadata_list.append(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load resume_data via DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"resume_data\", glob=\"*.txt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'resume_data\\\\Coco_Chanel_resume.txt'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [f\"resume_{str(i)}\" for i in range(1, len(docs)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectorstore\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents = docs,\n",
    "    embedding = embedding_function,\n",
    "    collection_name=\"full_resume\",\n",
    "    persist_directory='chroma/full_resume/',\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update docs with metadata_list\n",
    "for i in range(len(docs)):\n",
    "    docs[i].metadata = metadata_list[i]\n",
    "    vectordb.update_document(ids[i], docs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity search demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Machine learning engineer\"\n",
    "results = vectordb.similarity_search_with_score(\"software engineer with aws experience\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31041303277015686"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata:  {'filename': 'Johannes_Gutenberg_resume.txt', 'full_name': 'Johannes Gutenberg'}\n",
      "Score:  0.31041303277015686\n",
      "Metadata:  {'filename': 'Abraham_Lincoln_resume.txt', 'full_name': 'Abraham Lincoln'}\n",
      "Score:  0.3441496789455414\n",
      "Metadata:  {'filename': 'Roger_Federer_resume.txt', 'full_name': 'Roger Federer'}\n",
      "Score:  0.3596689701080322\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    \n",
    "    print(f'Metadata: ', result[0].metadata)\n",
    "    print('Score: ',result[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
